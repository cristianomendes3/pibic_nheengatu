import json
import numpy as np
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity

# Configura√ß√£o de Entrada
INPUT_FILE = "embeddings_extraidos.json"
OUTPUT_REPORT = "relatorio_similaridade_cosseno.csv"

def load_embeddings(filename):
    """Carrega o JSON e converte listas de volta para arrays numpy."""
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"‚úÖ Carregados {len(data)} pares de embeddings.")
        return data
    except FileNotFoundError:
        print(f"‚ùå Arquivo '{filename}' n√£o encontrado. Verifique se o script de extra√ß√£o foi executado.")
        return []
    except json.JSONDecodeError:
        print(f"‚ùå Erro ao decodificar o arquivo JSON '{filename}'.")
        return []

def calculate_similarities(data):
    """Calcula a similaridade de cosseno para cada par Nheengatu-Portugu√™s."""
    results = []
    
    print("--- Calculando Similaridades ---")
    
    for item in data:
        # Recupera vetores e garante que s√£o arrays 2D (1, 768)
        vec_yrl = np.array(item['vetor_yrl']).reshape(1, -1)
        vec_pt = np.array(item['vetor_pt']).reshape(1, -1)
        
        # Calcula Cosseno
        # O sklearn retorna uma matriz [[score]], pegamos o valor escalar com [0][0]
        similarity = cosine_similarity(vec_yrl, vec_pt)[0][0]
        
        # Armazena resultado usando as chaves corretas do novo JSON
        results.append({
            "Nheengatu": item.get('nheengatu_text', 'N/A'),
            "Portugues": item.get('portuguese_text', 'N/A'),
            # Metadados opcionais
            "Fonte": item.get('metadata', {}).get('raw_nheengatu', 'N/A'),
            "Similaridade": float(similarity) # Garante que √© um float Python puro
        })
        
    return results

def analyze_results(results):
    """Gera estat√≠sticas descritivas dos resultados."""
    if not results:
        print("Nenhum resultado para analisar.")
        return pd.DataFrame()

    df = pd.DataFrame(results)
    
    print("\n" + "="*40)
    print("RELAT√ìRIO DE VALIDA√á√ÉO CROSS-LINGUAL")
    print("="*40)
    
    # Estat√≠sticas Espec√≠ficas da Coluna de Similaridade
    sim_series = df['Similaridade']
    
    mean_sim = sim_series.mean()
    max_sim = sim_series.max()
    min_sim = sim_series.min()
    
    # Identificar os pares de maior e menor similaridade
    best_pair = df.loc[sim_series.idxmax()]
    worst_pair = df.loc[sim_series.idxmin()]

    print(f"M√©dia Geral de Similaridade: {mean_sim:.4f}")
    print(f"M√°xima: {max_sim:.4f} ('{best_pair['Nheengatu']}' <-> '{best_pair['Portugues']}')")
    print(f"M√≠nima: {min_sim:.4f} ('{worst_pair['Nheengatu']}' <-> '{worst_pair['Portugues']}')")
    
    # An√°lise por Faixas
    high_conf = len(df[df['Similaridade'] > 0.5])
    low_conf = len(df[df['Similaridade'] < 0.2])
    total = len(df)
    
    print(f"\nPares com Alta Similaridade (> 0.5): {high_conf} ({(high_conf/total)*100:.1f}%)")
    print(f"Pares com Baixa Similaridade (< 0.2): {low_conf} ({(low_conf/total)*100:.1f}%)")
    
    # Diagn√≥stico Interpretativo
    print("\n--- Diagn√≥stico ---")
    if mean_sim > 0.5:
        print("‚úÖ SUCESSO: O alinhamento cross-lingual √© forte.")
        print("   O modelo Canarim j√° possui boa correspond√™ncia com o portugu√™s.")
    elif mean_sim > 0.3:
        print("‚ö†Ô∏è ATEN√á√ÉO: Alinhamento moderado.")
        print("   Existe correspond√™ncia, mas ru√≠dos de tokeniza√ß√£o ou polissemia")
        print("   podem estar interferindo. Pode ser necess√°rio fine-tuning.")
    else:
        print("‚ùå CR√çTICO: Baixo alinhamento.")
        print("   Os espa√ßos vetoriais parecem distantes. Isso √© comum se os modelos")
        print("   n√£o foram treinados como bil√≠ngues pareados. Considere treinar")
        print("   uma matriz de proje√ß√£o linear (Orthogonal Procrustes).")

    return df

def main():
    data = load_embeddings(INPUT_FILE)
    if not data: return
    
    results = calculate_similarities(data)
    df = analyze_results(results)
    
    if not df.empty:
        # Salvar CSV para inspe√ß√£o humana
        df.to_csv(OUTPUT_REPORT, index=False, encoding='utf-8-sig', sep=';', float_format='%.4f')
        print(f"\nüìÑ Relat√≥rio detalhado salvo em: {OUTPUT_REPORT}")

if __name__ == "__main__":
    main()